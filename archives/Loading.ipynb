{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # import OpenCV\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm #pour barre de temps dans une boucle for\n",
    "from functions.Filtering import OTSU_threshold, filter_color_threshold,filter_Kmeans1,filter_Kmeans2,filter_MeanShift\n",
    "from functions.storing import database_generate,database_load\n",
    "from functions.machine_learning import modeling\n",
    "\n",
    "# from datetime import date\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who</th>\n",
       "      <th>date</th>\n",
       "      <th>savename</th>\n",
       "      <th>sample_per_cell_type</th>\n",
       "      <th>size</th>\n",
       "      <th>filter</th>\n",
       "      <th>preprocessing_status</th>\n",
       "      <th>preprocessing_time</th>\n",
       "      <th>saving_time</th>\n",
       "      <th>training_status</th>\n",
       "      <th>pca</th>\n",
       "      <th>pca_components</th>\n",
       "      <th>loading_time</th>\n",
       "      <th>train_test_split_time</th>\n",
       "      <th>RF_time</th>\n",
       "      <th>RF_train_acc</th>\n",
       "      <th>RF_test_acc</th>\n",
       "      <th>SVM_time</th>\n",
       "      <th>SVM_train_acc</th>\n",
       "      <th>SVM_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emilien</td>\n",
       "      <td>17/12/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>360x360</td>\n",
       "      <td>rgb</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>836.11</td>\n",
       "      <td>Done</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/</td>\n",
       "      <td>73.29</td>\n",
       "      <td>48.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775</td>\n",
       "      <td>65.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emilien</td>\n",
       "      <td>17/12/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>180x180</td>\n",
       "      <td>rgb</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.34</td>\n",
       "      <td>Done</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.24</td>\n",
       "      <td>7.07</td>\n",
       "      <td>9.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>14.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emilien</td>\n",
       "      <td>17/12/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>90x90</td>\n",
       "      <td>rgb</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.93</td>\n",
       "      <td>Done</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663</td>\n",
       "      <td>2.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emilien</td>\n",
       "      <td>17/12/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>360x360</td>\n",
       "      <td>rgb</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUT OF MEMORY</td>\n",
       "      <td>Done</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emilien</td>\n",
       "      <td>17/12/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>180x180</td>\n",
       "      <td>rgb</td>\n",
       "      <td>Done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2080.76</td>\n",
       "      <td>Done</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.06</td>\n",
       "      <td>2.07</td>\n",
       "      <td>107.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814</td>\n",
       "      <td>238.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       who        date savename  sample_per_cell_type      size filter  \\\n",
       "0  Emilien  17/12/2021      NaN                  50.0   360x360    rgb   \n",
       "1  Emilien  17/12/2021      NaN                  50.0   180x180    rgb   \n",
       "2  Emilien  17/12/2021      NaN                  50.0     90x90    rgb   \n",
       "3  Emilien  17/12/2021      NaN                 300.0   360x360    rgb   \n",
       "4  Emilien  17/12/2021      NaN                 300.0   180x180    rgb   \n",
       "\n",
       "  preprocessing_status  preprocessing_time    saving_time training_status pca  \\\n",
       "0                 Done                 NaN         836.11            Done  no   \n",
       "1                 Done                 NaN         163.34            Done  no   \n",
       "2                 Done                 NaN          18.93            Done  no   \n",
       "3                 Done                 NaN  OUT OF MEMORY            Done  no   \n",
       "4                 Done                 NaN        2080.76            Done  no   \n",
       "\n",
       "   pca_components loading_time  train_test_split_time RF_time  RF_train_acc  \\\n",
       "0             NaN            /                  73.29   48.27           NaN   \n",
       "1             NaN        36.24                   7.07    9.05           NaN   \n",
       "2             NaN         3.08                   0.05    1.45           NaN   \n",
       "3             NaN          NaN                    NaN     NaN           NaN   \n",
       "4             NaN       214.06                   2.07  107.32           NaN   \n",
       "\n",
       "  RF_test_acc SVM_time  SVM_train_acc SVM_test_acc  \n",
       "0       0.775    65.91            NaN        0.663  \n",
       "1        0.75    14.89            NaN        0.663  \n",
       "2       0.663     2.33            NaN        0.563  \n",
       "3         NaN      NaN            NaN          NaN  \n",
       "4       0.814   238.99            NaN        0.731  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp=pd.read_csv('variables/prep_info.csv')\n",
    "# df_exp.savename.dropna()\n",
    "df_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training database variables/data_prep/data_size-90x90_sample-500_f-Kmeans1.csv\n",
      "Time elapsed to load variables/data_prep/data_size-90x90_sample-500_f-Kmeans1.csv: 0.0min 4.0sec\n",
      "Time elapsed to train model: 2.0min 30.0sec\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feats_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13284/3519221361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# rf = RandomForestClassifier(max_depth=10, max_leaf_nodes=20) # on limite le nombre de feuilles et la profondeur pour éviter l'overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0macc_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0melapsed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplay_results_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;31m# df2.loc[idx,'train_test_split_time']=elapsed_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RF_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melapsed_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feats_pca' is not defined"
     ]
    }
   ],
   "source": [
    "df_exp=pd.read_csv('variables/prep_info.csv')\n",
    "idx=df_exp[df_exp.training_status=='Todo'].index # récupère les indexes des lignes à traiter\n",
    "# idx=df_exp[df_exp.Training_status=='Todo' & df_exp.savename.isna()==False].index\n",
    "\n",
    "for i in idx[:2]:\n",
    "    \n",
    "    savename = df_exp.loc[i,'savename']\n",
    "    size = tuple([int(x) for x in df_exp.loc[i,'size'].split('x')])\n",
    "    print(f'Training database {savename}')\n",
    "\n",
    "    data_df, elapsed_load = database_load(savename,size)\n",
    "\n",
    "    df_exp.loc[i,'loading_time']=round(elapsed_load,2)\n",
    "    \n",
    "    target = data_df['label'].apply(lambda x: x.split(' - ')[0])\n",
    "    feats = data_df.iloc[:,2:]\n",
    "\n",
    "    if df_exp.loc[i,'pca'] == 'yes':\n",
    "        # AVEC PCA\n",
    "        pca=PCA(n_components =0.9).fit(feats)\n",
    "        df_exp.loc[i,'pca_components']=pca.n_components_\n",
    "        # print('number of pixels kept:',pca.n_components_)\n",
    "        feats_pca=pca.transform(feats)\n",
    "        acc_train,acc_test,elapsed_train = modeling(feats_pca,target,svm.SVC(),display_results_list=[])\n",
    "    else:\n",
    "        # SANS PCA\n",
    "        acc_train,acc_test,elapsed_train = modeling(feats,target,svm.SVC(),display_results_list=[])\n",
    "    \n",
    "    # Enregistrement des résulats\n",
    "    df_exp.loc[i,'SVM_time']=round(elapsed_train,2)\n",
    "    df_exp.loc[i,'SVM_train_acc']=round(acc_train,3)\n",
    "    df_exp.loc[i,'SVM_test_acc']=round(acc_test,3)\n",
    "    \n",
    "    # rf = RandomForestClassifier(max_depth=10, max_leaf_nodes=20) # on limite le nombre de feuilles et la profondeur pour éviter l'overfitting\n",
    "    rf = RandomForestClassifier(max_depth=10)\n",
    "    acc_train,acc_test,elapsed_train = modeling(feats_pca,target,rf,display_results_list=[])\n",
    "    # df2.loc[idx,'train_test_split_time']=elapsed_split\n",
    "    df2.loc[idx,'RF_time']=round(elapsed_train,2)\n",
    "    df2.loc[idx,'RF_train_acc']=round(acc_train,3)\n",
    "    df2.loc[idx,'RF_test_acc']=round(acc_train,3)\n",
    "\n",
    "    df_exp.loc[i,'training_status']='Done'\n",
    "\n",
    "    df_exp.to_csv('variables/prep_info.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e33c57cfb312fffa7adc2d914c581c95b8c535429ce153970c14e4912b9006c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
